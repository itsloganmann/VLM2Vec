{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b997e7",
   "metadata": {},
   "source": [
    "# VLM2Vec MMEB-V2 Multi-Vector Benchmark\n",
    "\n",
    "This Colab notebook provisions an A100 40 GB workflow that installs pinned dependencies, clones the repo, materialises retriever modules, and evaluates vidore/colqwen2.5-v0.2, nvidia/llama-nemoretriever-colembed-3b-v1, and nomic-ai/colnomic-embed-multimodal-3b on MMEB-V2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ad3ef",
   "metadata": {},
   "source": [
    "## Runtime checklist\n",
    "- Select **GPU** runtime with **A100 40 GB**.\n",
    "- Ensure Google Drive access for persistent caches, logs, metrics, and resume state.\n",
    "- Run cells sequentially; smoke mode validates setup before running the full benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ac3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GPU_QUERY = [\"nvidia-smi\", \"--query-gpu=name,memory.total\", \"--format=csv,noheader\"]\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(GPU_QUERY).decode(\"utf-8\").strip().splitlines()\n",
    "except Exception as exc:\n",
    "    gpu_info = []\n",
    "    print(f\"nvidia-smi unavailable: {exc}\")\n",
    "\n",
    "print('Detected accelerators:')\n",
    "for line in gpu_info:\n",
    "    print(' -', line)\n",
    "\n",
    "state = {\"gpus\": gpu_info, \"is_a100\": any('A100' in line and ('40' in line or '40960' in line) for line in gpu_info)}\n",
    "Path('/content/work').mkdir(parents=True, exist_ok=True)\n",
    "with open('/content/work/gpu_detection.json', 'w') as fp:\n",
    "    json.dump(state, fp, indent=2)\n",
    "\n",
    "if not state['gpus']:\n",
    "    raise SystemExit('No NVIDIA GPU detected. Switch to an A100 runtime.')\n",
    "\n",
    "if state['is_a100']:\n",
    "    print('✅ NVIDIA A100 40 GB confirmed.')\n",
    "else:\n",
    "    print('⚠️ Running without A100. Switch to quick smoke preset and reduce batch sizes.')\n",
    "    print(json.dumps({\"device\": \"L4 24 GB\", \"adjustments\": {\"max_batch_queries\": 2, \"max_batch_docs\": 3, \"patch_budget\": 768}}, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture install_log\n",
    "%pip install -U pip==24.2\n",
    "%pip install torch==2.2.1+cu121 torchvision==0.17.1+cu121 torchaudio==2.2.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install transformers==4.44.0 accelerate==0.33.0 pillow==10.3.0 tqdm==4.66.5 numpy==1.26.4 pyyaml==6.0.2 datasets==2.20.0 huggingface-hub==0.23.4 sentencepiece==0.2.0 safetensors==0.4.3 einops==0.8.0 timm==1.0.7 pandas==2.2.2 rich==13.7.1 keybert==0.7.0 umap-learn==0.5.5 hdbscan==0.8.33 bertopic==0.16.0 evaluate==0.4.1 pynvml==11.5.0 pytest==8.3.2 pytest-cov==4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53797b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, torch, sys\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console(record=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(name)s | %(message)s')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "console.print(f'[bold green]Torch device[/bold green]: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \n",
    "}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from datetime import datetime\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "BASE = Path('/content/work')\n",
    "PERSIST = Path('/content/drive/MyDrive/vlm2vec')\n",
    "for path in [BASE, PERSIST, PERSIST / 'outputs', PERSIST / 'cache', PERSIST / 'logs', PERSIST / 'profiler']:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "print('Workspace ready:', BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019982bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "cd /content/work\n",
    "rm -rf VLM2Vec\n",
    "git clone https://github.com/itsloganmann/VLM2Vec.git\n",
    "pip install -e VLM2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424c3d4",
   "metadata": {},
   "source": [
    "## Materialise project assets\n",
    "The following cells copy repository configs, retriever modules, evaluation harness, and tests into `/content/work` so they can be executed and cached within the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "SRC = Path('/content/work/VLM2Vec')\n",
    "DST = Path('/content/work/runtime')\n",
    "if DST.exists():\n",
    "    shutil.rmtree(DST)\n",
    "shutil.copytree(SRC, DST)\n",
    "print('Copied project to', DST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4482b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.run(['pytest'], cwd='/content/work/runtime', check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093cd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/work/runtime/evaluation/multi_vector_eval.py --config /content/work/runtime/configs/mmeb_quick_smoke.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205700e6",
   "metadata": {},
   "source": [
    "## Full evaluation\n",
    "Run the full MMEB-V2 benchmark after the smoke test passes. Ensure the runtime remains connected (expect several hours on A100).\n",
    "\n",
    "```python\n",
    "!python /content/work/runtime/evaluation/multi_vector_eval.py --config /content/work/runtime/configs/mmeb_a100_full.yaml\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
